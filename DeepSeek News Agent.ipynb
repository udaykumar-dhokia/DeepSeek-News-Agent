{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade -q pandas smolagents streamlit groq newspaper3k duckduckgo-search beautifulsoup4 requests nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing DeepSeek_News_Agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile DeepSeek_News_Agent.py\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "from groq import Groq\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "class DuckDuckGoSearch:\n",
    "    \"\"\"\n",
    "    Custom DuckDuckGo search implementation with robust error handling and result processing.\n",
    "    Uses the duckduckgo_search library to fetch and format news results.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize the DuckDuckGo search session\n",
    "        self.ddgs = DDGS()\n",
    "\n",
    "    def __call__(self, query: str, max_results: int = 5) -> str:\n",
    "        try:\n",
    "            # Perform the search and get results\n",
    "            # The news method is more appropriate for recent news analysis\n",
    "            search_results = list(self.ddgs.news(\n",
    "                query,\n",
    "                max_results=max_results,\n",
    "                region='wt-wt',  # Worldwide results\n",
    "                safesearch='on'\n",
    "            ))\n",
    "\n",
    "            if not search_results:\n",
    "                return \"No results found. Try modifying your search query.\"\n",
    "\n",
    "            # Format the results into a readable string\n",
    "            formatted_results = []\n",
    "            for idx, result in enumerate(search_results, 1):\n",
    "                # Extract available fields with fallbacks for missing data\n",
    "                title = result.get('title', 'No title available')\n",
    "                snippet = result.get('body', result.get('snippet', 'No description available'))\n",
    "                source = result.get('source', 'Unknown source')\n",
    "                url = result.get('url', result.get('link', 'No link available'))\n",
    "                date = result.get('date', 'Date not available')\n",
    "\n",
    "                # Format each result with available information\n",
    "                formatted_results.append(\n",
    "                    f\"{idx}. Title: {title}\\n\"\n",
    "                    f\"   Date: {date}\\n\"\n",
    "                    f\"   Source: {source}\\n\"\n",
    "                    f\"   Summary: {snippet}\\n\"\n",
    "                    f\"   URL: {url}\\n\"\n",
    "                )\n",
    "\n",
    "            return \"\\n\".join(formatted_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Provide detailed error information for debugging\n",
    "            error_msg = f\"Search error: {str(e)}\\nTry again with a different search term or check your internet connection.\"\n",
    "            print(f\"DuckDuckGo search error: {str(e)}\")  # For logging\n",
    "            return error_msg\n",
    "\n",
    "class GroqLLM:\n",
    "    \"\"\"\n",
    "    LLM interface using Groq's LLama model.\n",
    "    Handles API communication and response processing.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"deepseek-r1-distill-llama-70b\"):\n",
    "        self.client = Groq(api_key=\"YOUR GRQ_API_KEY\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __call__(self, prompt: Union[str, dict, List[Dict]]) -> str:\n",
    "        try:\n",
    "            # Convert prompt to string if it's a complex structure\n",
    "            prompt_str = str(prompt) if isinstance(prompt, (dict, list)) else prompt\n",
    "\n",
    "            # Make API call to Groq\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt_str\n",
    "                }],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1024,\n",
    "                stream=False\n",
    "            )\n",
    "\n",
    "            return completion.choices[0].message.content if completion.choices else \"Error: No response generated\"\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error generating response: {str(e)}\"\n",
    "            print(error_msg)  # For logging\n",
    "            return error_msg\n",
    "\n",
    "def create_analysis_prompt(topic: str, search_results: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a detailed prompt for news analysis, structuring the request\n",
    "    to get comprehensive and well-organized results from the LLM.\n",
    "    \"\"\"\n",
    "    return f\"\"\"Analyze the following news information about {topic}.\n",
    "    Search Results: {search_results}\n",
    "\n",
    "    Please provide a comprehensive analysis including:\n",
    "    1. Key Points Summary:\n",
    "       - Main events and developments\n",
    "       - Critical updates and changes\n",
    "\n",
    "    2. Stakeholder Analysis:\n",
    "       - Primary parties involved\n",
    "       - Their roles and positions\n",
    "\n",
    "    3. Impact Assessment:\n",
    "       - Immediate implications\n",
    "       - Potential long-term effects\n",
    "       - Broader context and significance\n",
    "\n",
    "    4. Multiple Perspectives:\n",
    "       - Different viewpoints on the issue\n",
    "       - Areas of agreement and contention\n",
    "\n",
    "    5. Fact Check & Reliability:\n",
    "       - Verification of major claims\n",
    "       - Consistency across sources\n",
    "       - Source credibility assessment\n",
    "\n",
    "    Please format the analysis in a clear, journalistic style with section headers.\"\"\"\n",
    "\n",
    "def log_agent_activity(prompt: str, result: str, agent_name: str):\n",
    "    \"\"\"\n",
    "    Creates an expandable log of agent activities in the Streamlit interface\n",
    "    for transparency and debugging purposes.\n",
    "    \"\"\"\n",
    "    with st.expander(\"View Agent Activity Log\"):\n",
    "        st.write(f\"### Agent Activity ({agent_name}):\")\n",
    "        st.write(\"**Input Prompt:**\")\n",
    "        st.code(prompt, language=\"text\")\n",
    "        st.write(\"**Analysis Output:**\")\n",
    "        st.code(result, language=\"text\")\n",
    "\n",
    "# Initialize Streamlit app\n",
    "st.set_page_config(page_title=\"News Analysis Tool\", layout=\"wide\")\n",
    "\n",
    "# Title and description\n",
    "st.title(\"üîç AI News Analysis Tool\")\n",
    "st.write(\"\"\"\n",
    "This tool combines the power of Groq's üê¨DeepSeek-r1 Instant model with DuckDuckGo\n",
    "search to provide in-depth news analysis. Get comprehensive insights and multiple\n",
    "perspectives on any news topic.\n",
    "\"\"\")\n",
    "\n",
    "# Initialize the components\n",
    "try:\n",
    "    # Initialize LLM and search tool\n",
    "    llm = GroqLLM()\n",
    "    search_tool = DuckDuckGoSearch()\n",
    "\n",
    "    # Input section\n",
    "    news_topic = st.text_input(\n",
    "        \"Enter News Topic or Query:\",\n",
    "        placeholder=\"E.g., Recent developments in renewable energy\"\n",
    "    )\n",
    "\n",
    "    # Analysis options\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        search_depth = st.slider(\n",
    "            \"Search Depth (number of results)\",\n",
    "            min_value=3,\n",
    "            max_value=10,\n",
    "            value=5\n",
    "        )\n",
    "    with col2:\n",
    "        analysis_type = st.selectbox(\n",
    "            \"Analysis Type\",\n",
    "            [\"Comprehensive\", \"Quick Summary\", \"Technical\", \"Simplified\"]\n",
    "        )\n",
    "\n",
    "    # Generate analysis button\n",
    "    if st.button(\"Analyze News\"):\n",
    "        if news_topic:\n",
    "            with st.spinner(\"Gathering information and analyzing...\"):\n",
    "                try:\n",
    "                    # Show search progress\n",
    "                    search_placeholder = st.empty()\n",
    "                    search_placeholder.info(\"Searching for recent news...\")\n",
    "\n",
    "                    # Perform search\n",
    "                    search_results = search_tool(\n",
    "                        f\"Latest news about {news_topic} last 7 days\",\n",
    "                        max_results=search_depth\n",
    "                    )\n",
    "\n",
    "                    if not search_results.startswith((\"Search error\", \"No results\")):\n",
    "                        # Update progress\n",
    "                        search_placeholder.info(\"Analyzing search results...\")\n",
    "\n",
    "                        # Create analysis prompt\n",
    "                        analysis_prompt = create_analysis_prompt(news_topic, search_results)\n",
    "\n",
    "                        # Get analysis from LLM\n",
    "                        analysis_result = llm(analysis_prompt)\n",
    "\n",
    "                        # Clear progress messages\n",
    "                        search_placeholder.empty()\n",
    "\n",
    "                        # Display results\n",
    "                        st.subheader(\"üìä Analysis Results\")\n",
    "                        st.markdown(analysis_result)\n",
    "\n",
    "                        # Log the activity\n",
    "                        log_agent_activity(\n",
    "                            analysis_prompt,\n",
    "                            analysis_result,\n",
    "                            \"News Analysis Agent\"\n",
    "                        )\n",
    "                    else:\n",
    "                        search_placeholder.empty()\n",
    "                        st.error(search_results)\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.error(f\"An error occurred during analysis: {str(e)}\")\n",
    "        else:\n",
    "            st.warning(\"Please enter a news topic to analyze.\")\n",
    "\n",
    "    # Add helpful tips\n",
    "    with st.expander(\"üí° Tips for Better Results\"):\n",
    "        st.write(\"\"\"\n",
    "        - Be specific with your topic for more focused analysis\n",
    "        - Use keywords related to recent events for timely information\n",
    "        - Consider including timeframes in your query\n",
    "        - Try different analysis types for various perspectives\n",
    "        - For complex topics, start with a broader search and then narrow down\n",
    "        \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    st.error(f\"\"\"\n",
    "    Failed to initialize the application: {str(e)}\n",
    "\n",
    "    Please ensure:\n",
    "    1. Your GROQ_API_KEY is properly set in environment variables\n",
    "    2. All required packages are installed:\n",
    "       - pip install streamlit groq duckduckgo-search\n",
    "    3. You have internet connectivity for DuckDuckGo searches\n",
    "    \"\"\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.caption(\n",
    "    \"Powered by Groq LLama 3.1 8B Instant, DuckDuckGo, and Streamlit | \"\n",
    "    \"Created for news analysis and research purposes\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "added 22 packages in 5s\n",
      "\n",
      "3 packages are looking for funding\n",
      "  run `npm fund` for details\n"
     ]
    }
   ],
   "source": [
    "! npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
